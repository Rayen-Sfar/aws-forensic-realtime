#!/usr/bin/env python3
"""
advanced_analyzer.py - Analyseur forensic avanc√© pour AWS

Ce script analyse les logs CloudTrail et les m√©triques CloudWatch pour d√©tecter
des activit√©s malveillantes selon des r√®gles d√©finies. Il supporte :
- Corr√©lation entre √©v√©nements CloudTrail et m√©triques CloudWatch
- D√©tection de comportements anormaux bas√©e sur des seuils
- Enrichissement des alertes avec des donn√©es contextuelles
- Identification de patterns d'attaque connus (MITRE ATT&CK)
"""

import json
import boto3
import logging
import time
from datetime import datetime, timedelta
from botocore.exceptions import ClientError
from ioc_checker import is_malicious_ip

# Configuration du logging
logging.basicConfig(level=logging.INFO, 
                   format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# Configuration AWS
AWS_REGION = 'us-east-1'  # R√©gion par d√©faut, peut √™tre remplac√©e par un argument

class ForensicAnalyzer:
    """
    Analyseur forensic avanc√© qui traite les √©v√©nements AWS pour d√©tecter des activit√©s suspectes.
    """
    
    def __init__(self, rules_path='rules.json', region=AWS_REGION):
        """Initialise l'analyseur avec les r√®gles et la configuration."""
        self.rules = self.load_rules(rules_path)
        self.region = region
        self.cloudtrail = boto3.client('cloudtrail', region_name=region)
        self.cloudwatch = boto3.client('cloudwatch', region_name=region)
        self.ec2 = boto3.client('ec2', region_name=region)
        self.iam = boto3.client('iam')
        self.threat_intel_cache = {}  # Cache pour √©viter de faire trop d'appels API
        
    def load_rules(self, rules_path):
        """Charge les r√®gles depuis un fichier JSON."""
        try:
            with open(rules_path, 'r', encoding='utf-8') as f:
                rules = json.load(f)
            
            # Validation basique des r√®gles
            for rule in rules:
                required_fields = ['name', 'severity', 'condition']
                if not all(field in rule for field in required_fields):
                    logger.warning(f"R√®gle invalide (champs requis manquants): {rule.get('name', 'Sans nom')}")
            
            logger.info(f"Chargement r√©ussi de {len(rules)} r√®gles depuis {rules_path}")
            return rules
        except FileNotFoundError:
            logger.error(f"Fichier de r√®gles non trouv√©: {rules_path}")
            return []
        except json.JSONDecodeError as e:
            logger.error(f"Erreur de format JSON dans {rules_path}: {e}")
            return []
    
    def load_events_from_file(self, filepath):
        """Charge les √©v√©nements depuis un fichier JSON pour les tests."""
        try:
            with open(filepath, 'r', encoding='utf-8') as f:
                events = json.load(f)
            logger.info(f"Chargement de {len(events)} √©v√©nements depuis {filepath}")
            return events
        except Exception as e:
            logger.error(f"Erreur lors du chargement des √©v√©nements depuis {filepath}: {e}")
            return []
    
    def fetch_events_from_s3(self, bucket, prefix, max_events=1000):
        """R√©cup√®re les √©v√©nements CloudTrail stock√©s dans un bucket S3."""
        s3 = boto3.client('s3')
        events = []
        
        try:
            # Liste tous les objets dans le pr√©fixe sp√©cifi√©
            response = s3.list_objects_v2(Bucket=bucket, Prefix=prefix)
            
            if 'Contents' not in response:
                logger.warning(f"Aucun fichier trouv√© dans s3://{bucket}/{prefix}")
                return []
            
            # Traite chaque fichier CloudTrail
            count = 0
            for obj in response['Contents']:
                if count >= max_events:
                    break
                    
                if not obj['Key'].endswith('.json'):
                    continue
                    
                # T√©l√©charge et parse le fichier
                file_obj = s3.get_object(Bucket=bucket, Key=obj['Key'])
                file_content = file_obj['Body'].read().decode('utf-8')
                try:
                    data = json.loads(file_content)
                    if 'Records' in data:  # Format standard CloudTrail
                        events.extend(data['Records'])
                        count += len(data['Records'])
                    else:
                        events.append(data)  # Format de test simple
                        count += 1
                except json.JSONDecodeError:
                    logger.warning(f"Fichier non-JSON ignor√©: {obj['Key']}")
            
            logger.info(f"R√©cup√©ration de {len(events)} √©v√©nements depuis S3")
            return events
        except Exception as e:
            logger.error(f"Erreur lors de la r√©cup√©ration des √©v√©nements depuis S3: {e}")
            return []
    
    def query_cloudtrail_directly(self, lookback_hours=24):
        """Interroge CloudTrail directement via l'API pour les √©v√©nements r√©cents."""
        events = []
        try:
            end_time = datetime.utcnow()
            start_time = end_time - timedelta(hours=lookback_hours)
            
            paginator = self.cloudtrail.get_paginator('lookup_events')
            for page in paginator.paginate(
                StartTime=start_time,
                EndTime=end_time
            ):
                events.extend(page.get('Events', []))
                
            # Normalisation des √©v√©nements pour correspondre au format standard
            normalized_events = []
            for event in events:
                try:
                    # Les √©v√©nements de l'API lookup_events ont un format l√©g√®rement diff√©rent
                    # que nous devons normaliser
                    if 'CloudTrailEvent' in event:
                        cloud_trail_event = json.loads(event['CloudTrailEvent'])
                        normalized_events.append(cloud_trail_event)
                except (json.JSONDecodeError, KeyError):
                    logger.warning(f"Impossible de normaliser un √©v√©nement: {event}")
            
            logger.info(f"R√©cup√©ration de {len(normalized_events)} √©v√©nements depuis l'API CloudTrail")
            return normalized_events
        except Exception as e:
            logger.error(f"Erreur lors de la r√©cup√©ration des √©v√©nements depuis CloudTrail: {e}")
            return []
    
    def check_cloudwatch_metrics(self, instance_id, metric_name, namespace, threshold, period_minutes):
        """
        V√©rifie si une m√©trique CloudWatch d√©passe un seuil sur une p√©riode donn√©e.
        
        Args:
            instance_id: L'ID de l'instance EC2
            metric_name: Le nom de la m√©trique √† v√©rifier (ex: 'CPUUtilization')
            namespace: Le namespace CloudWatch (ex: 'AWS/EC2')
            threshold: La valeur seuil √† d√©passer
            period_minutes: La p√©riode sur laquelle v√©rifier (en minutes)
            
        Returns:
            tuple: (bool, float) - Un bool√©en indiquant si le seuil est d√©pass√© et la valeur max
        """
        try:
            end_time = datetime.utcnow()
            start_time = end_time - timedelta(minutes=period_minutes)
            
            response = self.cloudwatch.get_metric_statistics(
                Namespace=namespace,
                MetricName=metric_name,
                Dimensions=[{'Name': 'InstanceId', 'Value': instance_id}],
                StartTime=start_time,
                EndTime=end_time,
                Period=300,  # 5 minutes
                Statistics=['Maximum']
            )
            
            datapoints = response.get('Datapoints', [])
            if not datapoints:
                logger.warning(f"Aucune m√©trique trouv√©e pour {instance_id} sur {metric_name}")
                return False, 0
                
            max_value = max([point['Maximum'] for point in datapoints])
            is_above_threshold = max_value > threshold
            
            if is_above_threshold:
                logger.info(f"M√©trique {metric_name} pour {instance_id}: {max_value} > {threshold}")
            
            return is_above_threshold, max_value
            
        except ClientError as e:
            logger.error(f"Erreur CloudWatch pour {instance_id}: {e}")
            return False, 0
    
    def check_malicious_ip(self, ip_address):
        """
        V√©rifie si une IP est malveillante avec cache pour √©viter les appels r√©p√©t√©s.
        """
        if not ip_address or ip_address == "unknown":
            return False
            
        # Utilise le cache pour √©viter de faire trop d'appels API
        if ip_address in self.threat_intel_cache:
            return self.threat_intel_cache[ip_address]
            
        result = is_malicious_ip(ip_address)
        self.threat_intel_cache[ip_address] = result
        return result
        
    def enrich_event_with_context(self, event):
        """
        Enrichit un √©v√©nement avec des informations contextuelles suppl√©mentaires.
        """
        enriched_event = event.copy()
        
        try:
            # Enrichissement pour EC2
            if event.get('eventSource') == 'ec2.amazonaws.com' and event.get('eventName') == 'RunInstances':
                # R√©cup√©rer l'ID d'instance depuis la r√©ponse
                instance_id = None
                if 'responseElements' in event and 'instancesSet' in event['responseElements']:
                    items = event['responseElements']['instancesSet'].get('items', [])
                    if items:
                        instance_id = items[0].get('instanceId')
                
                if instance_id:
                    enriched_event['instance_details'] = {
                        'instance_id': instance_id
                    }
                    
                    # Ajoute des informations sur le type d'instance
                    try:
                        response = self.ec2.describe_instances(InstanceIds=[instance_id])
                        if response['Reservations']:
                            instance = response['Reservations'][0]['Instances'][0]
                            enriched_event['instance_details'].update({
                                'instance_type': instance.get('InstanceType'),
                                'launch_time': instance.get('LaunchTime'),
                                'vpc_id': instance.get('VpcId'),
                                'subnet_id': instance.get('SubnetId'),
                                'private_ip': instance.get('PrivateIpAddress'),
                                'public_ip': instance.get('PublicIpAddress')
                            })
                    except Exception as e:
                        logger.warning(f"Erreur lors de l'enrichissement EC2: {e}")
            
            # Enrichissement pour IAM
            if event.get('eventSource') == 'iam.amazonaws.com':
                user_name = None
                
                # R√©cup√©rer le nom d'utilisateur cible
                if event.get('eventName') == 'CreateAccessKey' and 'requestParameters' in event:
                    user_name = event['requestParameters'].get('userName')
                elif 'userIdentity' in event and 'userName' in event['userIdentity']:
                    user_name = event['userIdentity']['userName']
                    
                if user_name:
                    try:
                        # Obtenir des infos sur l'utilisateur
                        user_response = self.iam.get_user(UserName=user_name)
                        user = user_response.get('User', {})
                        enriched_event['user_details'] = {
                            'creation_date': user.get('CreateDate'),
                            'path': user.get('Path')
                        }
                        
                        # Obtenir les strat√©gies attach√©es
                        policies_response = self.iam.list_attached_user_policies(UserName=user_name)
                        enriched_event['user_details']['attached_policies'] = [
                            policy['PolicyName'] for policy in policies_response.get('AttachedPolicies', [])
                        ]
                    except Exception as e:
                        logger.warning(f"Erreur lors de l'enrichissement IAM: {e}")
        except Exception as e:
            logger.error(f"Erreur g√©n√©rale d'enrichissement: {e}")
            
        return enriched_event
        
    def evaluate_condition(self, event, condition):
        """
        √âvalue une condition de r√®gle par rapport √† un √©v√©nement.
        Supporte les conditions simples et les conditions complexes (AND, OR).
        """
        # Condition simple sur le nom de l'√©v√©nement
        if 'eventName' in condition:
            event_name_condition = condition['eventName']
            event_name = event.get('eventName')
            
            # Si la condition est une liste, on v√©rifie l'appartenance
            if isinstance(event_name_condition, list):
                if event_name not in event_name_condition:
                    return False
            # Sinon, on compare directement
            else:
                if event_name != event_name_condition:
                    return False
                    
        # Condition sur l'IP source (si elle est malveillante)
        if 'sourceIPIsMalicious' in condition and condition['sourceIPIsMalicious']:
            source_ip = event.get('sourceIPAddress')
            if not self.check_malicious_ip(source_ip):
                return False
                
        # Condition sur le nom du bucket S3
        if 'bucketName_startsWith' in condition:
            bucket_name = None
            if 'requestParameters' in event and 'bucketName' in event['requestParameters']:
                bucket_name = event['requestParameters']['bucketName']
                
            if not bucket_name or not bucket_name.startswith(condition['bucketName_startsWith']):
                return False
                
        # Condition sur le nombre d'√©v√©nements similaires
        # (Cette partie est complexe et n√©cessiterait une base de donn√©es pour √™tre efficace)
        # Dans cet exemple, nous simulons une d√©tection basique
        if 'frequency' in condition and condition['frequency'].get('enabled', False):
            # Dans une impl√©mentation r√©elle, il faudrait interroger une base de donn√©es
            # pour compter les √©v√©nements similaires dans la p√©riode sp√©cifi√©e
            # Pour cet exemple, on consid√®re que c'est toujours faux
            return False
            
        # Condition sur les m√©triques CloudWatch (pour le cryptojacking)
        if 'cloudwatch' in condition:
            cw_condition = condition['cloudwatch']
            
            # On a besoin d'un ID d'instance pour v√©rifier les m√©triques
            instance_id = None
            if 'instance_details' in event and 'instance_id' in event['instance_details']:
                instance_id = event['instance_details']['instance_id']
            elif 'responseElements' in event and 'instancesSet' in event['responseElements']:
                items = event['responseElements']['instancesSet'].get('items', [])
                if items:
                    instance_id = items[0].get('instanceId')
                    
            if instance_id:
                # V√©rifie si la m√©trique d√©passe le seuil
                is_above, value = self.check_cloudwatch_metrics(
                    instance_id,
                    cw_condition.get('metric', 'CPUUtilization'),
                    cw_condition.get('namespace', 'AWS/EC2'),
                    cw_condition.get('threshold', 90),
                    cw_condition.get('period_minutes', 60)
                )
                
                if not is_above:
                    return False
                    
                # Stocke la valeur pour l'inclure dans l'alerte
                event['cloudwatch_metrics'] = {
                    'cpu_utilization': value,
                    'cpu_high': is_above
                }
            else:
                # Pas d'instance ID, donc pas moyen de v√©rifier CloudWatch
                return False
                
        # Si toutes les conditions sont remplies, on retourne True
        return True

    def analyze_event(self, event):
        """
        Analyse un √©v√©nement selon les r√®gles d√©finies et retourne les alertes g√©n√©r√©es.
        """
        alerts = []
        
        # Enrichir l'√©v√©nement avec des informations contextuelles
        enriched_event = self.enrich_event_with_context(event)
        
        # √âvaluer chaque r√®gle
        for rule in self.rules:
            condition = rule.get('condition', {})
            
            # Si la r√®gle correspond, g√©n√©rer une alerte
            if self.evaluate_condition(enriched_event, condition):
                severity = rule['severity']
                
                # Augmenter la s√©v√©rit√© si l'IP est malveillante
                source_ip = enriched_event.get('sourceIPAddress')
                is_malicious = self.check_malicious_ip(source_ip)
                if is_malicious and severity != "CRITICAL":
                    severity = "CRITICAL"
                    
                # Cr√©er une structure d'alerte enrichie
                alert = {
                    "rule_id": rule.get('id', f"{enriched_event.get('eventSource', 'unknown').split('.')[0]}_001"),
                    "rule_name": rule['name'],
                    "severity": severity,
                    "category": rule.get('category', 'UNKNOWN'),
                    "event_details": {
                        "eventName": enriched_event.get('eventName'),
                        "sourceIP": enriched_event.get('sourceIPAddress'),
                        "userIdentity": enriched_event.get('userIdentity'),
                        "eventTime": enriched_event.get('eventTime')
                    },
                    "recommended_actions": rule.get('response', []),
                    "mitre_technique": rule.get('mitre_technique')
                }
                
                # Ajouter des infos sur l'instance pour les √©v√©nements EC2
                if 'instance_details' in enriched_event:
                    alert.update({"instance_id": enriched_event['instance_details'].get('instance_id')})
                    
                # Ajouter des m√©triques CloudWatch si disponibles
                if 'cloudwatch_metrics' in enriched_event:
                    alert.update(enriched_event['cloudwatch_metrics'])
                    
                # Ajouter des infos sur l'utilisateur pour les √©v√©nements IAM
                if 'user_details' in enriched_event:
                    alert.update({"user_details": enriched_event['user_details']})
                    
                # Marquer explicitement si l'IP est malveillante
                if is_malicious:
                    alert["is_malicious_ip"] = True
                    
                alerts.append(alert)
                
        return alerts

    def analyze_all_events(self, events):
        """
        Analyse une liste d'√©v√©nements et retourne toutes les alertes g√©n√©r√©es.
        """
        all_alerts = []
        event_count = len(events)
        logger.info(f"D√©but de l'analyse de {event_count} √©v√©nements")
        
        start_time = time.time()
        for i, event in enumerate(events):
            # Log de progression tous les 100 √©v√©nements
            if (i+1) % 100 == 0 or (i+1) == event_count:
                progress = (i+1) / event_count * 100
                elapsed = time.time() - start_time
                logger.info(f"Progression: {progress:.1f}% ({i+1}/{event_count}, {elapsed:.2f}s)")
                
            # Analyser l'√©v√©nement
            alerts = self.analyze_event(event)
            if alerts:
                all_alerts.extend(alerts)
                
        logger.info(f"Analyse termin√©e. {len(all_alerts)} alertes g√©n√©r√©es.")
        return all_alerts
        
    def run_analysis(self, source='s3', **kwargs):
        """
        Point d'entr√©e principal pour l'analyse.
        
        Args:
            source: Source des √©v√©nements ('s3', 'file', 'cloudtrail')
            **kwargs: Arguments sp√©cifiques √† la source
                - Pour 's3': bucket, prefix
                - Pour 'file': filepath
                - Pour 'cloudtrail': lookback_hours
        """
        events = []
        
        # Charger les √©v√©nements selon la source sp√©cifi√©e
        if source == 's3':
            bucket = kwargs.get('bucket')
            prefix = kwargs.get('prefix', 'cloudtrail/')
            events = self.fetch_events_from_s3(bucket, prefix)
        elif source == 'file':
            filepath = kwargs.get('filepath')
            events = self.load_events_from_file(filepath)
        elif source == 'cloudtrail':
            lookback_hours = kwargs.get('lookback_hours', 24)
            events = self.query_cloudtrail_directly(lookback_hours)
        else:
            logger.error(f"Source non reconnue: {source}")
            return []
            
        # Analyser les √©v√©nements
        if not events:
            logger.warning("Aucun √©v√©nement √† analyser.")
            return []
            
        alerts = self.analyze_all_events(events)
        
        # Sauvegarder les alertes si un chemin est sp√©cifi√©
        output_path = kwargs.get('output_path')
        if output_path and alerts:
            try:
                with open(output_path, 'w', encoding='utf-8') as f:
                    json.dump(alerts, f, indent=2, default=str)
                logger.info(f"Alertes sauvegard√©es dans {output_path}")
            except Exception as e:
                logger.error(f"Erreur lors de la sauvegarde des alertes: {e}")
                
        return alerts


# Fonction principale pour l'ex√©cution standalone
def main():
    """
    Point d'entr√©e pour ex√©cuter l'analyseur depuis la ligne de commande.
    """
    import argparse
    
    parser = argparse.ArgumentParser(description="Analyseur forensic avanc√© pour AWS")
    parser.add_argument('--rules', default='rules.json', help="Chemin vers le fichier de r√®gles")
    parser.add_argument('--region', default=AWS_REGION, help="R√©gion AWS")
    parser.add_argument('--output', help="Chemin du fichier de sortie pour les alertes")
    
    # Arguments pour les sources de donn√©es
    source_group = parser.add_mutually_exclusive_group(required=True)
    source_group.add_argument('--s3', action='store_true', help="Utiliser S3 comme source")
    source_group.add_argument('--file', action='store_true', help="Utiliser un fichier local comme source")
    source_group.add_argument('--cloudtrail', action='store_true', help="Utiliser l'API CloudTrail directement")
    
    # Arguments sp√©cifiques aux sources
    parser.add_argument('--bucket', help="Nom du bucket S3 (avec --s3)")
    parser.add_argument('--prefix', default='cloudtrail/', help="Pr√©fixe dans le bucket S3 (avec --s3)")
    parser.add_argument('--filepath', help="Chemin du fichier d'√©v√©nements (avec --file)")
    parser.add_argument('--lookback', type=int, default=24, help="Nombre d'heures √† analyser (avec --cloudtrail)")
    
    args = parser.parse_args()
    
    # Initialiser l'analyseur
    analyzer = ForensicAnalyzer(rules_path=args.rules, region=args.region)
    
    # D√©terminer la source et ex√©cuter l'analyse
    if args.s3:
        if not args.bucket:
            parser.error("--bucket est requis avec --s3")
        alerts = analyzer.run_analysis('s3', bucket=args.bucket, prefix=args.prefix, output_path=args.output)
    elif args.file:
        if not args.filepath:
            parser.error("--filepath est requis avec --file")
        alerts = analyzer.run_analysis('file', filepath=args.filepath, output_path=args.output)
    elif args.cloudtrail:
        alerts = analyzer.run_analysis('cloudtrail', lookback_hours=args.lookback, output_path=args.output)
    
    # Afficher un r√©sum√© des alertes
    if alerts:
        print(f"\nüö® {len(alerts)} alerte(s) d√©tect√©e(s) !")
        
        # Grouper par s√©v√©rit√©
        severity_counts = {}
        for alert in alerts:
            severity = alert.get('severity', 'UNKNOWN')
            severity_counts[severity] = severity_counts.get(severity, 0) + 1
            
        # Afficher un r√©sum√© par s√©v√©rit√©
        for severity, count in severity_counts.items():
            print(f"  {severity}: {count} alerte(s)")
            
        # Montrer le d√©tail des alertes CRITICAL
        critical_alerts = [a for a in alerts if a.get('severity') == 'CRITICAL']
        if critical_alerts:
            print("\n‚ö†Ô∏è Alertes CRITIQUES :")
            for alert in critical_alerts:
                print(f"  - {alert.get('rule_name')} ({alert.get('event_details', {}).get('eventName')})")
    else:
        print("Aucune alerte d√©tect√©e.")


if __name__ == "__main__":
    main()